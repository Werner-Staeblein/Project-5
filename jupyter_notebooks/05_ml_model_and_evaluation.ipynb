{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **House Price Prediction with Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* Fit ML regression model for prediction of sale price of inherited houses and any other house in the region\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* Cleaned dataset\n",
    "* outputs/datasets/cleaned/HousePricesCleaned.csv\n",
    "* Variables determined in the data cleaning and feature engineering notebook\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* ML pipeline for house price prediction \n",
    "\n",
    "## Conclusions\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\My_Folders\\\\CodeInstitute\\\\Project_5_files\\\\Project-5\\\\Project-5\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MWW8E7lz3i7"
   },
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\My_Folders\\\\CodeInstitute\\\\Project_5_files\\\\Project-5\\\\Project-5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1 content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>...</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>706</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>548</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
       "0       856     854.0           3.0           No         706          GLQ   \n",
       "1      1262       0.0           3.0           Gd         978          ALQ   \n",
       "2       920     866.0           3.0           Mn         486          GLQ   \n",
       "\n",
       "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
       "0        150            0.0         548          RFn  ...         65.0   \n",
       "1        284            NaN         460          RFn  ...         80.0   \n",
       "2        434            0.0         608          RFn  ...         68.0   \n",
       "\n",
       "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
       "0       196.0          61            5            7          856         0.0   \n",
       "1         0.0           0            8            6         1262         NaN   \n",
       "2       162.0          42            5            7          920         NaN   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  SalePrice  \n",
       "0       2003          2003     208500  \n",
       "1       1976          1976     181500  \n",
       "2       2001          2002     223500  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"outputs/datasets/collection/house_prices.csv\") \n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQo3ycuO-v6"
   },
   "source": [
    "# ML Pipeline: Regression\n",
    "## Libraries for ML pipeline must be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "### Data Cleaning Step\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "\n",
    "### Feature Engineering Step\n",
    "from feature_engine import creation\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from feature_engine import transformation as vt\n",
    "from feature_engine.outliers import Winsorizer\n",
    "\n",
    "### Feature Scaling Step\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### Feature Selection Step\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "### ML algorithms to be applied\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the ML pipeline\n",
    "\n",
    "- The pipeline steps for data cleaning and feature engineering combined in PipelineOptimization\n",
    "- This step applies the defined preprocessing of data before a ML model is applied\n",
    "- The features included in drop/mean/median etc are those determined in the previous notebook steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2 content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline optimization\n",
    "def PipelineOptimization(model):\n",
    "  pipeline_base = Pipeline([\n",
    "    # Data cleaning (copied from Data Cleaning notebook)\n",
    "     ( 'drop',  DropFeatures(features_to_drop=['EnclosedPorch', 'WoodDeckSF', 'GarageFinish', 'BsmtFinType1', 'BsmtExposure'])),\n",
    "\n",
    "     ( 'mean',  MeanMedianImputer(imputation_method='mean',\n",
    "                                     variables=['LotFrontage', 'BedroomAbvGr']) ),\n",
    "\n",
    "     ( 'median',  MeanMedianImputer(imputation_method='median',\n",
    "                                     variables=['2ndFlrSF', 'GarageYrBlt', 'MasVnrArea']) ),\n",
    "   \n",
    "    # ( 'categorical',  CategoricalImputer(imputation_method='missing',\n",
    "    #                                  fill_value='Unf',\n",
    "    #                                  variables=[]) ),\n",
    "\n",
    "    # Feature engineering (copied from Feature Engineering notebook)\n",
    "    (\"OrdinalCategoricalEncoder\",OrdinalEncoder(encoding_method='arbitrary', \n",
    "                                                  variables = ['KitchenQual'])),\n",
    "    \n",
    "    ('lt', vt.LogTransformer(variables = ['GrLivArea', 'LotArea', 'LotFrontage']) ),\n",
    "\n",
    "    ('pt', vt.PowerTransformer(variables = ['GarageArea', 'MasVnrArea', 'OpenPorchSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF']) ),\n",
    "       \n",
    "      \n",
    "    (\"Winsoriser_iqr\",Winsorizer(capping_method='iqr', fold=1.5, tail='both', \n",
    "                                                  variables=['1stFlrSF',\n",
    "                                                             '2ndFlrSF',\n",
    "                                                             'GarageArea',\n",
    "                                                             'LotArea',\n",
    "                                                             'LotFrontage',\n",
    "                                                             'MasVnrArea',\n",
    "                                                             'OpenPorchSF',\n",
    "                                                             'TotalBsmtSF',\n",
    "                                                      ])),      \n",
    "       \n",
    "    (\"SmartCorrelatedSelection\",SmartCorrelatedSelection(variables= None,\n",
    "       method=\"spearman\", threshold=0.8,selection_method=\"variance\") ),\n",
    "\n",
    "    (\"feat_scaling\", StandardScaler() ),\n",
    "\n",
    "    (\"feat_selection\",  SelectFromModel(model) ),\n",
    "\n",
    "    (\"model\", model ),\n",
    "    ])\n",
    "\n",
    "  return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Class for hyperparameter optimisation\n",
    "\n",
    "- code copied from walkthrough project of Code Institute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model=  PipelineOptimization(self.models[key])\n",
    "\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Train set: (1168, 23) (1168,) \n",
      "* Test set: (292, 23) (292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test = train_test_split(\n",
    "                                    df.drop(['SalePrice'], axis=1) ,\n",
    "                                    df['SalePrice'],\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0\n",
    "                                    )\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Cross-Validation - Sklearn\n",
    "\n",
    "- Search for the best hyperparameter for ML model with cross-validation, i.e. the data is split into subsets. The model is trained on one of those subsets and tested against the remainder of the subsets not used as train subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 in hyperparameter optimisation | default hyperparameters to determine best algorithm\n",
    "\n",
    "- In the first step, the best model is determined based on default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "# Code taken from Scikit-learn videos/instructions\n",
    "params_quick_search = {\n",
    "    \"LinearRegression\": {},\n",
    "\n",
    "    \"DecisionTreeRegressor\": {'model__max_depth': [None,4, 15],\n",
    "                             'model__min_samples_split': [2,50],\n",
    "                             'model__min_samples_leaf': [1,50],\n",
    "                             'model__max_leaf_nodes': [None,50],\n",
    "        },\n",
    "\n",
    "    \"RandomForestRegressor\": {'model__n_estimators': [100,50, 140],\n",
    "                             'model__max_depth': [None,4, 15],\n",
    "                             'model__min_samples_split': [2,50],\n",
    "                             'model__min_samples_leaf': [1,50],\n",
    "                             'model__max_leaf_nodes': [None,50],\n",
    "        },\n",
    "\n",
    "    \"ExtraTreesRegressor\": {'model__n_estimators': [100,50,150],\n",
    "        'model__max_depth': [None, 3, 15],\n",
    "        'model__min_samples_split': [2, 50],\n",
    "        'model__min_samples_leaf': [1,50],\n",
    "        },\n",
    "\n",
    "    \"AdaBoostRegressor\": {'model__n_estimators': [50,25,80,150],\n",
    "                          'model__learning_rate':[1,0.1, 2],\n",
    "                          'model__loss':['linear', 'square', 'exponential'],\n",
    "        },\n",
    "\n",
    "    \"GradientBoostingRegressor\": {'model__n_estimators': [100,50,140],\n",
    "                                  'model__learning_rate':[0.1, 0.01, 0.001],\n",
    "                                  'model__max_depth': [3,15, None],\n",
    "                                  'model__min_samples_split': [2,50],\n",
    "                                  'model__min_samples_leaf': [1,50],\n",
    "                                  'model__max_leaf_nodes': [None,50],\n",
    "        },\n",
    "\n",
    "    \"XGBRegressor\": {'model__n_estimators': [30,80,200],\n",
    "                    'model__max_depth': [None, 3, 15],\n",
    "                    'model__learning_rate': [0.01,0.1,0.001],\n",
    "                    'model__gamma': [0, 0.1],\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- determine best hyperparameters for each model selected (the model from model_quick_search). Hyperparameters that are tested are taken from params_quick_search\n",
    "- Models selected are trained on X_train and y_train with a five-foled cross-validation (cv)\n",
    "- Model performance is determined with R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for LinearRegression \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for DecisionTreeRegressor \n",
      "\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Running GridSearchCV for RandomForestRegressor \n",
      "\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      "Running GridSearchCV for ExtraTreesRegressor \n",
      "\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Running GridSearchCV for AdaBoostRegressor \n",
      "\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Running GridSearchCV for GradientBoostingRegressor \n",
      "\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Running GridSearchCV for XGBRegressor \n",
      "\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltNetd085qHf"
   },
   "source": [
    "# Push files to Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKlnIozA4eQO",
    "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
